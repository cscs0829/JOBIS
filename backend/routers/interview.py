# Routers/interview.py
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from openai import OpenAI
from typing import Dict, List
import os
from dotenv import load_dotenv # load_dotenvë¡œ .env íŒŒì¼ì— api í‚¤ ê°€ì ¸ì˜´
import asyncpg
from DB.Connection import get_db_connection

# VectorDB ê´€ë¦¬ ì¶”ê°€ 4/23 ì¶”ê°€
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()

router = APIRouter(tags=["interview"])

openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class DetailInsertRequest(BaseModel):
    intr_idx: int
    talk_person: str
    talk_content: str

class Message(BaseModel):
    role: str
    content: str

# Pydantic ëª¨ë¸
class InterviewStartRequest(BaseModel):
    persona: str
    job: str
    interviewType: str
    selectedMode: str
    mem_id: str # ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰ì„ ìœ„í•´ í•„ìš”!
    messages: list[Message]

class InterviewRequest(BaseModel):
    persona: str
    job: str
    interviewType: str
    selectedMode: str
    messages: list[Message]

class QuestionFeedback(BaseModel):
    question: str
    answer: str
    feedback: str
    score: int

class InterviewFeedbackData(BaseModel):
    overallScore: int
    scores: Dict[str, int]
    questionFeedbacks: List[QuestionFeedback]
    finalFeedback: str

# ì‹¤ì œ DB insert í•¨ìˆ˜
async def create_interview_session(persona: str, job: str, interviewType: str, mem_id: str):
    conn = await get_db_connection()
    query = """
        INSERT INTO tb_interview (interviewer_psna, interviewed_at, mem_id)
        VALUES ($1, NOW(), $2)
        RETURNING intr_idx
    """
    combined_psna = f"{persona} / {job} / {interviewType}"
    row = await conn.fetchrow(query, combined_psna, mem_id)
    await conn.close()
    return row["intr_idx"]

# @router.get("/db_test")
# async def db_test():
#     try:
#         conn = await get_db_connection()
#         result = await conn.fetch("SELECT 1")
#         await conn.close()
#         return {"messages":"DB ì—°ê²° ì„±ê³µ!", "result": [dict(row) for row in result]}
#     except Exception as e:
#         return {"error": str}

@router.post("/save-detail")
async def save_detail(req: DetailInsertRequest):
    conn = await get_db_connection()
    try:
        print(f"ğŸ’¡ ìš”ì²­ ë°ì´í„°: intr_idx={req.intr_idx}, talk_person={req.talk_person}, talk_content={req.talk_content}")
        await conn.execute("""
            INSERT INTO tb_detail (intr_idx, talk_person, talk_content, talk_tm)
            VALUES ($1, $2, $3, NOW())
        """, req.intr_idx, req.talk_person, req.talk_content)
        await conn.close()
        return {"msg": "âœ… detail ì €ì¥ ì™„ë£Œ"}
    except Exception as e:
        await conn.close()
        return {"error": str(e)}

@router.get("/debug/interview-check")
async def test_insert():
    try:
        conn = await get_db_connection()
        row = await conn.fetchrow("SELECT * FROM tb_interview LIMIT 1")
        await conn.close()
        if row is None:
            return {"message": "í…Œì´ë¸”ì€ ì¡´ì¬í•˜ì§€ë§Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        return {"sample_row": dict(row)}
    except Exception as e:
        return {"error": str(e)}

@router.post("/start")
async def start_interview(req: InterviewStartRequest):
    try:
        print("ğŸ’¡ ìš”ì²­ ë°ì´í„°:", req)
        session_id = await create_interview_session(
            persona=req.persona,
            job=req.job,
            interviewType=req.interviewType,
            mem_id=req.mem_id
        )
        print("âœ… ì„¸ì…˜ ìƒì„± ì™„ë£Œ:", session_id)
        return {"session_id": session_id}
    except Exception as e:
        print("âŒ ì˜ˆì™¸ ë°œìƒ:", e)
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/interview")
async def interview(req: InterviewRequest):
    prompt = [
        {
            "role": "system",
              "content": (
                f"ë‹¹ì‹ ì€ {req.persona}ë¼ëŠ” ì„±ê²©ì˜ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. "
                f"ì§ë¬´ëŠ” {req.job}ì´ê³ , ë©´ì ‘ ìœ í˜•ì€ {req.interviewType}ì…ë‹ˆë‹¤. "
                "ë©´ì ‘ê´€ìœ¼ë¡œì„œ ì§€ì›ìì—ê²Œ í•œ ë²ˆì— í•˜ë‚˜ì”© ì§ˆë¬¸ì„ í•˜ì„¸ìš”."
                
                ),
              },
        *[msg.dict() for msg in req.messages]
    ]

    try:
        # OpenAI API í˜¸ì¶œ
        openai.api_key = os.getenv("OPENAI_API_KEY")
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=prompt,
            temperature=0.7
        )

        reply = response.choices[0].message.content
        return {"reply": reply}
    except Exception as e:
       return {"error": str(e)}
    
async def score_answer_with_ai(question: str, answer: str) -> int:
    prompt =f"""
        ë‹¤ìŒì€ ì§€ì›ìì™€ ë©´ì ‘ê´€ì˜ ëŒ€í™”ì…ë‹ˆë‹¤.

        [ì§ˆë¬¸]
        {question}

        [ë‹µë³€]
        {answer}

        [í‰ê°€ ê¸°ì¤€]
        - ë‹µë³€ì˜ êµ¬ì²´ì„±, ëª…í™•ì„±, ì§ë¬´ ê´€ë ¨ì„±, ìì‹ ê° ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.
        - 0ì ë¶€í„° 100ì  ì‚¬ì´ë¡œ ë§¤ê¸°ì„¸ìš”. (1ì  ë‹¨ìœ„)
        - ì ìˆ˜ë§Œ ìˆ«ì í•˜ë‚˜ë¡œ ì¶œë ¥í•˜ì„¸ìš”. (ì˜ˆ: 87)

        ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”:
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )

        raw_score = response.choices[0].message.content.strip()
        score = int(raw_score)
    except Exception as e:
        print(f"score_answer_with_ai ì‹¤íŒ¨: {e}")
        score = 70 # í˜¹ì‹œ ì´ìƒí•œ ê°’ ë‚˜ì˜¤ë©´ ê¸°ë³¸ ê°’
    return score

async def generate_final_feedback_with_ai(all_answers: List[str]) -> str:
    combined_answers = "\n\n".join(all_answers)

    prompt = f"""
        ë‹¤ìŒì€ ì§€ì›ìì˜ ëª¨ë“  ë©´ì ‘ ë‹µë³€ì…ë‹ˆë‹¤.

        [ë‹µë³€ ëª¨ìŒ]
        {combined_answers}

        [ìš”ì²­ ì‚¬í•­]
        - ì „ë°˜ì ì¸ ë‹µë³€ ìˆ˜ì¤€ì„ í‰ê°€í•˜ê³  ìµœì¢… í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.
        - ì§€ì›ìê°€ ì˜í•œ ì ê³¼ ê°œì„ í•  ì ì„ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì œì‹œí•˜ì„¸ìš”.
        - 3~4ì¤„ ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        - ë„ˆë¬´ ë¶€ë“œëŸ½ê±°ë‚˜ ëª¨í˜¸í•˜ì§€ ì•Šê²Œ, êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

        ìµœì¢… í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”:
    """

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "user", "content": prompt}
        ],
        temperature=0.4
    )

    final_feedback = response.choices[0].message.content.strip()
    return final_feedback

def generate_individual_feedback_with_ai(question: str, answer: str) -> str:
    prompt =f"""
        ë‹¤ìŒì€ ë©´ì ‘ ì§ˆë¬¸ê³¼ ì´ì— ëŒ€í•œ ì§€ì›ìì˜ ë‹µë³€ì…ë‹ˆë‹¤. ì´ ë‹µë³€ì— ëŒ€í•´ ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.

        - ì–´ë–¤ ì ì´ ë¶€ì¡±í•œì§€
        - ì–´ë–»ê²Œ ê°œì„ í•  ìˆ˜ ìˆëŠ”ì§€
        - 1~2 ë¬¸ì¥ ì´ë‚´, ë‹¨ìˆœí•œ í‘œí˜„ì€ í”¼í•˜ê³ , êµ¬ì²´ì ì´ê³  ì‹¤ì§ˆì ì¸ ì¡°ì–¸ì„ ì œì‹œí•˜ì„¸ìš”.

        [ì§ˆë¬¸]
        {question}

        [ë‹µë³€]
        {answer}

        í”¼ë“œë°±:
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        print("GPT ì‘ë‹µ ê²°ê³¼:", response)
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"generate_individual_feedback_with_ai ì‹¤íŒ¨: {e}")
        return "ë‹µë³€ì€ ë¹„êµì  ì„±ì‹¤í–ˆì§€ë§Œ, í•µì‹¬ ì „ë‹¬ë ¥ì´ ë‹¤ì†Œ ë¶€ì¡±í–ˆìŠµë‹ˆë‹¤."

@router.get("/{session_id}/feedback", response_model=InterviewFeedbackData)
async def get_interview_feedback(session_id: str):
    try:
        conn = await get_db_connection()
        # 1. tb_detail í…Œì´ë¸”ì—ì„œ ì„¸ì…˜ì— í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸/ë‹µë³€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        rows = await conn.fetch("""
                SELECT talk_person, talk_content
                FROM tb_detail
                WHERE intr_idx = $1
                ORDER BY talk_tm ASC
        """, int(session_id))

        print(f"session_id = {session_id} rows ê°œìˆ˜ = {len(rows)}")
    except Exception as e:
        print(f"DB ì¡°íšŒ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail="DB ì¡°íšŒ ì‹¤íŒ¨")
    finally:
        await conn.close()

    if not rows:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì— í•´ë‹¹í•˜ëŠ” ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # 2. ì§ˆë¬¸-ë‹µë³€ ìŒ êµ¬ì„±
    questions_feedback = []
    current_question = None
    for row in rows:
        if row["talk_person"] == "interviewer":
            if "ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤" in row["talk_content"]:
                continue
            current_question = row["talk_content"]
        elif row["talk_person"] == "interviewee" and current_question:
            score = await score_answer_with_ai(current_question, row["talk_content"])
            feedback = generate_individual_feedback_with_ai(current_question, row["talk_content"])
            questions_feedback.append(
                QuestionFeedback(
                    question=current_question,
                    answer=row["talk_content"],
                    feedback=feedback,
                    score=score
                )
            )
            current_question = None # ì§ˆë¬¸-ë‹µë³€ ì§ ë§ì¶”ê³  ë‚˜ë©´ ì´ˆê¸°í™”

    if not questions_feedback:
        return InterviewFeedbackData(
            overallScore=0,
            scores={
                "clarity": 0,
                "relevance": 0,
                "confidence": 0,
                "professionalism": 0,
                "conciseness": 0,
            },
            questionFeedbacks=[],
            finalFeedback="ë‹µë³€ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    
    all_answers = [q.answer for q in questions_feedback]
    final_feedback = await generate_final_feedback_with_ai(all_answers)
    overall_score = sum(q.score for q in questions_feedback) // len(questions_feedback)

    import random
    scores = {
        "clarity": min(100, max(0, overall_score + random.randint(-5, 5))),
        "relevance": min(100, max(0, overall_score + random.randint(-5, 5))),
        "confidence": min(100, max(0, overall_score + random.randint(-5, 5))),
        "professionalism": min(100, max(0, overall_score + random.randint(-5, 5))),
        "conciseness": min(100, max(0, overall_score + random.randint(-5, 5))),
    }

    # 3. ì „ì²´ í”¼ë“œë°± ë°ì´í„° êµ¬ì„±
    return InterviewFeedbackData(
        overallScore=overall_score,
        scores=scores,
        questionFeedbacks=questions_feedback,
        finalFeedback=final_feedback
    )