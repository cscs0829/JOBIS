from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
import json
import os
import requests
from bs4 import BeautifulSoup

# âœ… selenium ê´€ë ¨ ëª¨ë“ˆ
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# âœ… ë³‘ë ¬ ì²˜ë¦¬ìš©
import concurrent.futures

# âœ… ê¸€ë¡œë²Œ ë©˜í†  ìºì‹œ (ë©”ëª¨ë¦¬ìš©)
mentor_cache = {}

# âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ê²½ë¡œ (path ì˜µì…˜ ì œê±°: êµ¬ë²„ì „ í˜¸í™˜)
CHROMEDRIVER_PATH = ChromeDriverManager().install()

# âœ… ë©˜í†  ì œëª© í¬ë¡¤ë§ + ìºì‹±
def get_mentor_description_from_detail(link: str) -> str:
    if link in mentor_cache:
        return mentor_cache[link]

    try:
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")

        driver = webdriver.Chrome(service=Service(CHROMEDRIVER_PATH), options=chrome_options)
        driver.get(link)
        driver.implicitly_wait(1)  # ë¹ ë¥´ê²Œ ëë‚´ê¸°

        soup = BeautifulSoup(driver.page_source, "html.parser")
        driver.quit()

        title_tag = soup.select_one("h1")
        if title_tag:
            text = title_tag.get_text(strip=True)
            result = f"ì´ ë©˜í† ëŠ” {text}"
            mentor_cache[link] = result
            print(f"âœ… ë©˜í†  ì œëª© ìºì‹± ì™„ë£Œ: {text}")
            return result
        else:
            print("âŒ ì œëª© íƒœê·¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ Selenium íŒŒì‹± ì‹¤íŒ¨: {e}")

    return "ì´ ë©˜í† ëŠ” í˜„ì§ìì˜ ì‹¤ì „ ë©˜í† ë§ì„ ì œê³µí•©ë‹ˆë‹¤."


# âœ… ë©˜í†  ì¶”ì²œ ê¸°ëŠ¥
def recommend_mentors_from_query(query: str):
    cache_path = f"data/mentor_reco_cache_{query}.json"
    if os.path.exists(cache_path):
        print("âš¡ ìºì‹œì—ì„œ ì¶”ì²œ ê²°ê³¼ ë¶ˆëŸ¬ì˜´")
        with open(cache_path, "r", encoding="utf-8") as f:
            return json.load(f)

    search_url = f"https://itdaa.net/classes?search={query}"
    response = requests.get(search_url, headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(response.text, "html.parser")
    class_cards = soup.select("a[href^='/meetings/']")

    print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼ ì¹´ë“œ ìˆ˜: {len(class_cards)}")

    seen_links = set()
    mentor_links = []

    for card in class_cards:
        link = "https://itdaa.net" + card["href"]
        if link in seen_links:
            continue
        seen_links.add(link)
        mentor_links.append(link)
        if len(mentor_links) >= 5:
            break

    # âœ… ë³‘ë ¬ ì‹¤í–‰ (ìµœëŒ€ 2ê°œ ë™ì‹œì—)
    with concurrent.futures.ProcessPoolExecutor(max_workers=2) as executor:
        descriptions = list(executor.map(get_mentor_description_from_detail, mentor_links))

    # âœ… ê²°ê³¼ êµ¬ì„±
    recommended = []
    for idx, (link, nickname) in enumerate(zip(mentor_links, descriptions)):
        recommended.append({
            "id": idx,
            "nickname": nickname,
            "company": "itdaa ì¶”ì²œ í´ë˜ìŠ¤",
            "techStack": [],
            "mentoringTopics": [],
            "targetMentees": [],
            "yearsExperience": "",
            "price": None,
            "meetingType": "",
            "meetingLocation": "",
            "link": link
        })

    # âœ… JSON ìºì‹œ ì €ì¥
    os.makedirs("data", exist_ok=True)
    with open(cache_path, "w", encoding="utf-8") as f:
        json.dump(recommended, f, ensure_ascii=False, indent=2)

    print("ğŸŸ¢ ì¶”ì²œ ê²°ê³¼:", recommended)
    return recommended
